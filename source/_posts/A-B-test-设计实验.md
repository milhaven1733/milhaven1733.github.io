---
title: A/B test 设计实验
date: 2017-05-29 17:10:51
tags:
categories: 数据分析
---

#### 概述

为实验设计做出必要决策：

-  choose subject（将总体中的哪些diversion选为测试对象）
-  choose population （选定测试的整体对象范围，保证测试和评估指标施加于同等整体）
-  size （确定实验规模）
-  duration（确定实验时长）

<!---more--->

#### 关于选择对象 

随机分配对象至对照组或实验组。

对于用户可见的更改，要将更改分配到特定人群，而非（点击）事件。

##### 如何定义“人群”？

在线测试中，选定一个“人”的 **unit  of diversion(分组单元)**

- 根据用户ID（可能有多个账户）
- 根据cookie （更换浏览器或设备，出现不同的cookie）

#### 分组单元

常用分组单元：

- user id

  - stable unchanging
  - personally identifiable

- anonymous ID（cookie）匿名标识

  - change when you switch browser or device
  - can clear cookie，much easier to change

- event

  no consistent experience

  （多适用于用户不可见或不易察觉的更改，如更改排序列表）

less common:

- device id

  - only available for mobile
  - tied to specific device
  - unchangeable by user

- IP address

  - change when location changes

  不具备一致性

示例：

![](A-B-test-设计实验\1.png)

勾选的选项表示事件发生时，会被分配至某一组或组别被更改。"?"表示可能发生更改但不确定

#### 分组的一致性

- 用户一致性

  对于某些测试，如课程展示效果，要保证同一用户在不同设备下体验一致。

- 登录前后体验一致性

  如果变更页面效果，需要使用cookie分组保证同一设备下登录前后体验一致

对于用户可见更改，一定会使用ID或cookie分组。

但对于不可见更改（如后台架构、延迟变化、排序变化），要根据测量内容决定分组形式

如，测试用户在某项变更后的学习效果，更改延迟后的用户量变化还是需要stateful unit of diversion

IP address 分组：

会随机变化，不具备一致性，无法提供随机结果，分析较难。

但有些变更必须使用IP分组，如：

测试架构变化，需要在两个主机服务商之间做比较

无法便捷得到对照组和实验组的效果对比

分组单元选择示例：

![](A-B-test-设计实验\2.png)

- 用户通常无法察觉视频加载速度，排序结果的变化，对于短期实验，只需基于事件分组，但对于长期效果的评估，可以基于cookie分组
- 为保证刷新每一次时变更存在，且不需保证不同设备间变更一致，可以基于cookie分组
- 确定变更是否影响特定用户的学习效果，在不同设备间一致性很重要，需要基于ID分组

#### 分组的道德考虑

需要考虑收集的是哪些数据，数据能否被辨识。

如基于ID分组，数据一定是可辨识的，需要处理所有安全与保密问题，需要合理获得用户许可。

基于事件或cookie分组，不一定得知用户身份，知情同意不一定必须。

示例：

![](A-B-test-设计实验\3.png)

#### 分组的差异性、unit of analysis

根据经验计算得出的差异性可能会高于分析方法计算得出的差异性

当分析单元不同于分组单元时，以上现象常见。

unit of analysis——指标分母，如：计算点击率时的总页面查看量

如果基于页面查看（event）分组，差异性会较小，但基于ID和cookie分组，差异较大

原因：

根据分析方法计算差异性，需要对数据分布情况，独立性作出假设。

当根据event分组时，可以保证独立性，但根据ID、cookie分组时，独立性无效。

差异性比较：

![](A-B-test-设计实验\4.png)

分组单元与分析单元一致时，SE较小，更接近分析估计

示例：

哪个案例的分析方差最接近经验方差？![](A-B-test-设计实验\5.png)

第一个案例，两个单元不同，差异较大。

第三个案例，分析单元和分组单元均为用户ID，差异更接近

第二个案例，分析单元是一天内的cookie活动，由于一个cookie会产生多个页面查看，分析单元大于分组单元。

由页面查看（event）分组，某cookie下的事件可能同时被分入实验与对照组，实验设计不准确。

#### 目标人群

inter-user experiments 用户间实验——为实验的A/B组分配不同的用户。

如何定位用户：

利用浏览器、地理区域、语言、用户已使用时长、用户人口信息来定位user space中某个特定个体

限制参与实验用户数量的场景：

- 测试发布风险较高、不确定是否发布的新功能
- 测试版本针对特定的语言/地区
- 不确定新版本兼容性
- 同时进行多个测试、避免用户重叠
- 避免全局总体稀释实验效果

仅针对可能受实验影响的人群开展实验（流量筛选），会影响差异性。

示例：

分析一项仅影响新西兰用户的更改，针对新西兰用户开展实验：

$$ 对照组Ncont=6021,Xcont=302$$

$$ 实验组Nexp=5979,Xexp=374$$

$$\hat Pcont=\frac{Xcont}{Ncont}=5.1\% $$

$$\hat Pexp=\frac{Xexp}{Nexp}=6.3\%$$

$$合并概率 \hat{P}_{pool}=\frac{Xcont+Xexp}{Ncont+Nexp}=0.056 $$

![](A-B-test-设计实验\6.png)

假设更改不影响所有非新西兰流量，则针对其他用户展开测试，得到结果：

$$ 对照组Ncont=50000,Xcont=2500$$

$$ 实验组Nexp=50000,Xexp=2500$$

计算总体标准误差及仅针对新西兰用户和针对全局的测试结果是否具有统计显著性差异。

Global Calculations：

$$ Ncont=6021+50000=56021,Xcont=302+2500=2802$$

$$ Nexp=5979+50000=55979,Xexp=374+2500=2874$$

$$\hat P_{pool}=0.051,SE_{pool}=0.0013$$

可以看出，过滤后的数据呈现的差异性更大。

计算全局差异：

$$\hat d=\hat{Pexp}-\hat{Pcont}=0.0013$$

$$m=SEpool*1.96=0.0025$$

置信区间包含0，即差异不具有显著性

针对新西兰数据：

$$\hat d=\hat{Pexp}-\hat{Pcont}=0.012$$

$$m=SEpool*1.96=0.0082$$

置信区间不包含0，即具有显著差异

（新西兰数据观察到的差异更大，而全局数据稀释了这个差异）

#### cohorts（队列）

population&cohort差别:

某些原因可能导致population中的用户加入或退出实验，且参与时长不一。

可以在population基础上define a entering class——仅关注大约相同时间加入A/B组的用户以及限制之后加入的用户，作为cohort。

何时使用cohort：

通常仅在观察用户稳定性时使用。

如：观察学习成果，衡量网站 、移动设备使用增长等根据用户历史表现了解更改是否对用户行为产生重大影响的情况

#### Size

容量选取为一个迭代过程。将尝试选择不同的分组单元和目标人群，查看对于实验规模和持续时间的影响。

要点：

- 确定规模过程
- 关于设计考虑因素：实验持续时间、风险因素、相关决策过程

##### 样本容量

需要首先考虑影响差异性的因素，如指标选择、分组单元、总体等

如：基于用户ID分组，测试页面加载延迟对网站使用率的影响

由于对于全局进行实验、耗时长，成本高，可以进一步确定关注目标，如近两个月经常使用网站的用户。

尽管限制缩小了实验范围，但在实际投入时间执行大规模实验前进行，对肯定实验意义具有帮助。

示例：基于pageview和cookie分组时得到的SE的差异和只要需要收集数据量的对比![](A-B-test-设计实验\7.png)



#### 如何减小实验样本容量

现针对一项实验：更改各门课程的显示顺序，测试各课程页面总点击率的变化

指标：任何课程的总点击量/（课程列表）页面查看次数

分组单元：cookie

当前实验得到显著结果所需要收集数据的周期过长，如何减少获得结果所需的总页面查看次数？

- $$increase\ dmin,\alpha,\beta（增大统计、实际显著性界限，即不检测较小的更改或接受较高的误判概率）$$

- 将分组单元更改为pageview

  降低指标差异性（能使SE减小，从而降低页面查看次数）

- target experiment to specific traffic

  统计不受更改影响的用户产生的数据会稀释结果。

  但需要注意，由于特定流量数据总体较小，可能不会缩短收集数据的周期，但我们可以同时针对其他用户流量开展其他实验

  同时，流量筛选可能影响实际显著性界限的选择——针对用户流量子集，可能需要做出更显著的更改，或由于差异性较低，可以利用这一优势检测较小的更改

有些实验在实施之前，实际无法确定受影响的部分，例如：

为页面涉及改善方案，不确定对于哪种浏览器影响效果最大。

更改应用具有的语言检测功能，难以准确预料哪些用户将受影响。

总而言之——难以为实验直接设定目标

这种情况下，规划实验持续时间、规模时，应相对保守。可以先开展一个短期的试点实验或根据第一天/周的数据来观察或预测总体中最受影响的部分。

#### 持续时间

有以下要点：

- 实验持续多长时间

- 何时开展实验

- what fraction of traffic to send through the experiment

  如需要为实验组、对照组采集共100万cookie，每日总流量为10万cookie，当将流量的50%分配给实验组，50%分配至对照组，实验需持续10天，如果减少流量发送比率，则实验将持续更久。

  为什么不总针对所有流量开展实验？

  - safety

    不确定新功能运行是否正常，不确定用户反馈。应该仅对部分用户实验直到得到满意结果

  - press

    不确定新功能是否上线前不宜大规模公布

  - other thing impact the variability

    如某天的流量由于特殊原因出现较大差异，倾向于针对较小比例流量开展持续多天的实验

  - multiple task

    针对相同功能开展多个试验任务（如设置不同参数、针对功能不同类型），可以应用较小比例流量同时开展实验

  另外，由于每天获得的流量数目不同（如每周中有一定规律的周期变化），且指标也会根据周期发生相应变异。为了保证收集足够流量以及减少变更的风险，应该针对组合时段收集较小比例数据开展实验。

出于风险考虑限制实验规模延长实验时间案例：

- 更改后台数据库
- 使网站支持Facebook登录（若更改最终不上线，无法处理之前使用Facebook登录的账户数据）
- 更改课程列表排列顺序 （如果是首次更改，有可能因漏洞导致课程无法显示）

#### 学习效应

learning-effects——衡量用户是否适应更改

首次看到更改时，用户通常产生两种反应——抵触或新奇的心理。但随时间发展会产生不同行为

time——measure the effect

tips：

- 衡量学习效应，需使用“stateful unit”，如cookie、user ID
- 学习效率还取决于用户看到更改的周期——“dosage”——使用cohort