---
title: A/B tests概览
date: 2017-05-11 20:35:48
tags:
categories: 数据分析
---

#### A/B tests

##### 作用

通过尝试可能的改变，寻找用户更喜欢的方式，更科学的确定如何优化网站或移动应用——根据数据作出决定。

##### 步骤：

- 设计任务
- 选择指标
- 分析结果

#### 关于A/B test

用于在线测试的常规方法，用来测试新产品或新功能。

<!---more--->

#### 何时使用A/B tests

不适合使用的情境：

- 在线购物网站：网站是否全面、是否存在用户想购买但无法提供的商品

  （测试无法确认是否提供了所有商品）

- 免费使用的网站考虑是否提供更高级的付费功能

  （无法全面测试高级服务是否是好的商业决策）

- 汽车销售网站：考虑变更是否使顾客再次访问网站或向朋友推荐

  （短时间内无法测试效果）

- 某家公司：测试改变品牌logo的效果

  （改变logo对于客户冲击较大，可能需要时间适应，短时间内采集的数据意义不大）

适合使用的情境：

- 为用户提供电影推荐的网站：测试新的推荐排序算法

  （有明确的对照组和实验组和明确的评估改变的指标）

- 是否改变网站基础架构的后台（可能影响页面加载速度、用户可以看到的显示结果等）

  （如果计算机能够同时运行两个版本，则可以对变化结果进行测试）

- 某移动应用：测试改变应用首页的效果

  （明确的对照组和实验组、更容易选择评估改变的指标）

#### 其他技巧

对于A/B test不太适用的场景，可以运用其他收集用户数据的方式加以测试或对A/B test进行补充，如：

- 通过检查或观察记录用户在网站上的操作日志得出造成用户行为改变的原因的假设，并设计实验，完成随机化实验和前瞻性分析（验证假设的过程与AB测试可以互为补充）
- 从用户体验研究到focus group、调查和人为评价得出许多深入的定性数据作为AB测试得到的宽泛的定量数据的补充

#### 在线A/B test 的特点

区别于医学上的临床实验和传统农业领域上的测试，在线A/B test具有特点：

- 数据量大，但分辨率低（很难真正得知用户的具体信息）

A/B test目的：

确认用户是否喜欢新的产品或功能，必须设计一个合理且返回可复验的结果的测试。

#### 商业案例概述

对于教育网站“Audacity”,对用户行为构建客户漏斗模型，开始设计一个简单的测试过程，验证对网站主页进行某项变更后是否增加探索课程的学生，即从漏斗模型的第一层（homepage visits）移动到第二层（exploring the site）

#### 度量选择

如何定量地测量“改进”的效果：

- 完成课程的学生数量？ 完成课程时间过长，作为测量指标太耗时间，不现实。
- 进入课程页面按钮的实际点击量？ 有意义但不能反映各实验组的比率。
- 点击（比）率 $$(\frac{Number\ of\ clicks}{Number\ of\ page\ views})$$ 部分用户可能不止点击一次，使结果参考性降低
- 点击概率 $$(\frac{unique\ visitors\ who\ clicks}{unique\ visitors\ to\ page})$$

通常来说，测试可用性选择比率（测试某个按钮在众多按钮中被点击的频繁性），测试总影响采用概率（测试进入二级页面的用户比率）

将假设更新为，变更将提高按钮的点击概率（并假设最终可以提高终极业务指标——课程完成总数）

#### 估计点击概率

- 变更网站，捕捉用户点击事件。
- 计算比率：计算页面访问总数和点击总数
- 计算概率：对于每个页面访问，仅计算一个子点击（将每个页面访问匹配所有子点击）

#### 重复实验

在得到一组数据并根据数据做出预测后，需要重复进行测量。

#### 分布类型

由于是否点击的数据不是连续数据，而是有成功失败两种结果，适合使用二项分布对结果进行分析。

#### 关于二项分布

对于一项试验，成功的概率为p，失败的概率为（1-p），当增大试验次数N时，成功概率的分布会趋近于正态分布

$$mean=p$$

$$std=\sqrt{\frac{p(1-p)}{N}}$$ 

(p越接近0.5，N越大，则分布越紧凑)

二项分布使用条件：

- 必须有两个不同结果
- 事件必须独立
- 事件要遵循同一种分布

#### 置信区间

可以使用样本二项分布的标准误差公式来估计整体概率的变化程度。

如果置信区间为95%，则不断重复试验，最终得到均值附近的区间，有95%几率覆盖真正的值。

一般经验：

![](A-B-test概览\5.png)

可以将二项分布的模型j假设为正态分布

则置信区间宽度 

![](A-B-test概览\6.png)

$$如当前\ \hat{p}=0.1,\alpha=0.05,N=1000,则z=1.96(双尾检验)\ m=0.019 $$

则当前置信区间为：[0.081,0.119],即点击概率有95%的可能在0.08～0.12之间

#### 建立显著统计性

构建假设检验：

将对照组点击概率称为Pcont，	实验组称为Pexp

$$H_0:Pexp-Pcont=0$$

$$H_A:Pexp-Pcont\ne0$$

预估采集到的数据中的$$\hat{Pexp}-\hat{Pcont}$$

与零假设做比较，检验其出现的概率是否在置信区间内，根据结果判断是否拒绝零假设。

#### 合并标准误差

由于我们具有两组样本，在对比时，我们需要选取一个标准误差以方便对比

将两组中的点击用户数称为Xcont和Xexp，总用户数称为Ncont和Nexp

$$合并点击概率 \hat{P}_{pool}=\frac{Xcont+Xexp}{Ncont+Nexp}$$

合并标准误差 

![](A-B-test概览\4.png)



$$\hat{d}=\hat{Pexp}-\hat{Pcont}$$

$$H_0:d=Pexp-Pcont=0$$

$$则\hat{d}若大于1.96*SE_{pool}或小于其负值，则拒绝零假设$$

#### 实质性显著性

从商业角度来决定，怎样的点击概率变化具有实际显著性。

适当地设计实验规模。选取我们感兴趣的变更程度的实际显著性边界。

#### 权衡样本容量及功效

在进行试验前，我们需要确定，我们应怎样控制对照组和实验组的网页浏览量，以获取最具统计显著性的结果——即统计功效

通常功效和规模呈负相关关系——想要探测的改变越小，需要运行实验规模就越大

#### 样本量N对敏感性的影响

增大N时，分布变窄，意味着保持同样的显著性，拒绝零假设的临界值更接近0

当两样本有差异，且具备实际显著性（如0.02）时，实际分布右移：

![](A-B-test概览\1.png)

$$从图像可以看出，两分布有较大重叠，即零假设错误但没有拒绝零假设的概率很大，将这个值称为\beta$$

所以：

$$收集少量样本时 \alpha\ low,\beta\ high$$

即得到错误结论的概率较大

当差异越大时，错误的概率会越小

$$通常将1-\beta 称为敏感性$$

一般在实际显著性范围内，希望实验具备更高敏感性，通常选择80%

样本量增大时，分布形状更紧凑

![](A-B-test概览\2.png)

当真正出现差异时，无法拒绝零假设的几率大大减小。

$$收集大量样本时 \alpha\ same,\beta\  lower$$

#### 计算每组所需页面浏览量

在进行实验时，需要确定为保证一定敏感性所需的N值，可以利用[在线计算器](http://www.evanmiller.org/ab-testing/sample-size.html) 来计算此数值

需要输入变更前的预计点击概率、实际显著性、敏感性和统计显著性，可得出每组实验需要的数据量

当变更一些参数时N的变化：

当预计点击概率升高（小于0.5）时，标准误差会增加，需要增大N使标准误差保持原有水平。

增大实际显著性时，更容易探测到变化，可以适当减少N

增大置信程度或敏感性，需要增大N，使分布更紧密

#### 置信区间案例分析

#### ![](A-B-test概览\3.png)

蓝线为实际显著性界限，点估计的置信区间范围为如上几种情况：

- 当边界两端均大于实际显著性界限，变更在极大程度上可能超过实际显著性，选择发布变更版本
- 第二种情况，中性变更，不值得发布
- 第三种情况，不具有实际显著性，不值得发布
- 第四种情况，较难处理置信区间超出实际显著性范围，可能得到相反的结果，建议采用功效更大的实验
- 第五六种情况也较难处理，可以认为具有实际显著性，但也可能无法得到具有实际显著性的结果，甚至得到相反的结果，同样建议采用功效更大的测试

#### 对不确定数据作出决策

对于如上几种不确定性的数据，如果必须作出决策，需要依赖其他因素，如战略业务问题或数据背后的其他因素来决定。